# StickLLM Directory Structure

```
stickllm/
â”‚
â”œâ”€â”€ ğŸ“„ README.md                    # Main documentation
â”œâ”€â”€ ğŸ“„ SETUP_SUOCOMMERCE.md            # Setup guide for Suocommerce use case
â”œâ”€â”€ ğŸ“„ QUICKREF.md                  # Quick reference card
â”œâ”€â”€ ğŸ“„ LICENSE                      # MIT License
â”‚
â”œâ”€â”€ ğŸš€ launch.sh                    # Launch script (Linux/Mac)
â”œâ”€â”€ ğŸš€ launch.bat                   # Launch script (Windows)
â”œâ”€â”€ ğŸ”§ setup.sh                     # Automated setup script
â”‚
â”œâ”€â”€ ğŸ“ cli/                         # Command-line interface
â”‚   â”œâ”€â”€ stickllm.py                 # Main CLI application
â”‚   â”œâ”€â”€ config.yaml                 # Configuration file
â”‚   â””â”€â”€ requirements.txt            # Python dependencies
â”‚
â”œâ”€â”€ ğŸ“ models/                      # AI model files (GGUF format)
â”‚   â””â”€â”€ README.md                   # Model download instructions
â”‚   â””â”€â”€ [your .gguf files here]
â”‚
â”œâ”€â”€ ğŸ“ runtime/                     # Platform-specific binaries
â”‚   â”œâ”€â”€ linux/
â”‚   â”‚   â””â”€â”€ [llama-server binary]
â”‚   â”œâ”€â”€ macos/
â”‚   â”‚   â””â”€â”€ [llama-server binary]
â”‚   â””â”€â”€ windows/
â”‚       â””â”€â”€ [llama-server.exe]
â”‚
â”œâ”€â”€ ğŸ“ context/                     # Project documentation & context
â”‚   â””â”€â”€ suocommerce/
â”‚       â”œâ”€â”€ architecture.md         # Example architecture doc
â”‚       â””â”€â”€ [add your docs here]
â”‚
â””â”€â”€ ğŸ“ chats/                       # Conversation history
    â””â”€â”€ sessions.db                 # SQLite database (auto-created)
```

## After Setup, You'll Have:

```
stickllm/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ deepseek-coder-6.7b-instruct.Q5_K_M.gguf     (~5GB)
â”‚   â””â”€â”€ deepseek-coder-33b-instruct.Q4_K_M.gguf     (~20GB)
â”‚
â”œâ”€â”€ runtime/
â”‚   â””â”€â”€ [your-platform]/
â”‚       â””â”€â”€ llama-server                              (~50-100MB)
â”‚
â”œâ”€â”€ context/
â”‚   â””â”€â”€ suocommerce/
â”‚       â”œâ”€â”€ architecture.md
â”‚       â”œâ”€â”€ commandos-overview.md
â”‚       â””â”€â”€ tech-stack.md
â”‚
â””â”€â”€ chats/
    â””â”€â”€ sessions.db                                   (grows over time)
```

## Total Size Breakdown

| Component | Size | Notes |
|-----------|------|-------|
| Base files | <1MB | Scripts, docs, config |
| llama.cpp binary | ~50-100MB | Per platform |
| Small model (6.7B) | ~5GB | Fast responses |
| Large model (33B) | ~20GB | Deep reasoning |
| Context docs | ~1MB | Your project documentation |
| Chat history | Grows | SQLite database |
| **Minimal setup** | **~6GB** | One small model |
| **Recommended setup** | **~25GB** | Both models |
| **Available space (1TB)** | **~975GB** | For your work files |

## Key Files Explained

### Launch Scripts
- **launch.sh** / **launch.bat** - Detects OS, starts llama.cpp server, launches CLI
- Auto-detects available models and platform

### CLI Application
- **stickllm.py** - Main Python application with terminal interface
- Handles chat sessions, context management, server communication
- Similar UX to Claude Code

### Configuration
- **config.yaml** - Personas, model settings, context presets
- Customize for your workflow

### Models
- GGUF format (quantized for efficiency)
- Larger = better quality but slower
- Q4/Q5 = quantization level (4-bit, 5-bit)

### Context
- Add project documentation here
- Automatically loaded into AI conversations
- Helps AI understand your specific codebase/architecture

### Chats
- SQLite database stores all conversations
- Sessions can be resumed
- Full history maintained across devices
